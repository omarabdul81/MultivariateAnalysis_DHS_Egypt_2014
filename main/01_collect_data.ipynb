{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff7aacf-4beb-4901-b8ef-2cf1b13013f6",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d8992af-5104-4166-b248-7bdb5f1a9a9c",
   "metadata": {},
   "source": [
    "This module processes raw survey data from Egypt and prepares it for analysis.\n",
    "It extracts metadata like variable names, IDs, data types, and categorical levels (for categorical data).\n",
    "It also converts data files from STATA (.DTA) format to CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f857e8-3e9f-40e5-9a40-41ddedf1201f",
   "metadata": {},
   "source": [
    "## Configure Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf80c0d-9ed9-40c1-add4-10ce6edf50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running this module for the first time, you may need to install the required third-party packages.\n",
    "# Steps:\n",
    "# 1. Uncomment the line below and run the cell to install the packages.\n",
    "# 2. Check the log to confirm successful installation.\n",
    "# 3. Comment the line back out and restart the module.\n",
    "\n",
    "# !pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bbaeb0-55cc-4792-bf70-0d45f753449d",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d411728-fc34-41ac-804e-fa106e596924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e1e34-2d46-45ed-89fc-7d98824058c9",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cead3921-b089-4f76-90e1-8dc1f2ee5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_files(zip_path: str, extract_to: str):\n",
    "    \"\"\"\n",
    "    Unzips all files from the specified zip archive to a given directory.\n",
    "\n",
    "    :param zip_path: Path to the zip file.\n",
    "    :param extract_to: Destination directory for extracted files.\n",
    "    \"\"\"\n",
    "    # Validate if the provided path points to a valid zip file\n",
    "    if not zipfile.is_zipfile(zip_path):\n",
    "        raise ValueError(f\"{zip_path} is not a valid zip file.\")\n",
    "    \n",
    "    # Open the zip file and extract its contents to the target directory\n",
    "    with zipfile.ZipFile(file=zip_path, mode=\"r\") as my_zip_file:\n",
    "        my_zip_file.extractall(path=extract_to)\n",
    "\n",
    "    # Confirmation of successful extraction\n",
    "    print(f\"Extracted all files to {extract_to}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a9e445-b4f9-4ea0-b489-91ccff41b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mydir(dirname: str) -> Path:\n",
    "    \"\"\"\n",
    "    Creates a directory, including parent directories if they do not exist.\n",
    "\n",
    "    :param dirname: The path of the directory to create.\n",
    "    :return: Path object representing the created directory.\n",
    "    \"\"\"\n",
    "    path = Path(dirname)\n",
    "    # Create the directory, along with any necessary parent directories\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0764196-02d7-4fca-8b29-b06554aa76ca",
   "metadata": {},
   "source": [
    "## Process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c59185a-c4be-44a4-afd1-ae9a1443f9e8",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba66b1c6-4c7d-47b7-af66-6575cdf844f2",
   "metadata": {},
   "source": [
    "#### Target Country: Eygpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae1bb94c-7896-4407-9494-9ad1318eadc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target country for data processing\n",
    "country = \"EG\"\n",
    "\n",
    "# Create a directory to store raw data files, including parent directories if they don't exist\n",
    "raw_data_dir = make_mydir('../resources/raw_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0b316a-cde1-42d4-93d4-67c59d11ca46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the source data zip folder name: EG_2014_DHS_07092024_715_216139.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted all files to ..\\resources\\raw_data\\extracted\\all\\EG\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to provide the path to the zipped raw survey data\n",
    "# In the current investigation, we use the following as folder as a source raw data: \n",
    "# EG_2014_DHS_07092024_715_216139.zip\n",
    "raw_data_file = input(\"Enter the name of the source data zip folder name:\")\n",
    "\n",
    "# Construct the full path to the user-provided zip file\n",
    "raw_data_path = f'../user_input/{raw_data_file}'\n",
    "\n",
    "# Create a directory for extracting the raw data, specific to the target country\n",
    "extract_to = make_mydir(f\"{raw_data_dir}/extracted/all/{country}/\")\n",
    "\n",
    "# Unzip the provided raw data file to the specified directory\n",
    "unzip_files(zip_path=raw_data_path, extract_to=extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477e4897-5e58-409b-991c-24f61a811332",
   "metadata": {},
   "source": [
    "### Extract variables metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c58a8f-0622-4637-8bc6-62ff2db3c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_data(directory_path: str, var_output_file_path: str,\n",
    "                          var_level_output_file_path: str, var_type_output_file_path: str,\n",
    "                          data_output_file_dir: str):\n",
    "    \"\"\"\n",
    "    Processes raw survey data files from a specified directory and extracts metadata (variable names, levels, and types). \n",
    "    Converts data from STATA format to CSV.\n",
    "\n",
    "    :param directory_path: Path to the directory containing the raw files.\n",
    "    :param var_output_file_path: Path to the output file where variable names will be saved.\n",
    "    :param var_level_output_file_path: Path to the output file for variable levels.\n",
    "    :param var_type_output_file_path: Path to the output file for variable types.\n",
    "    :param data_output_file_dir: Path to the directory where converted CSV files will be saved.\n",
    "    \"\"\"\n",
    "    DELIMIT = \",\"  # Delimiter for output files\n",
    "    file_count = 0  # Tracks number of files processed\n",
    "    start_time = time.time()  # To calculate processing time\n",
    "\n",
    "    try:\n",
    "        print(\"Processing raw data files...\")\n",
    "        \n",
    "        # Initialize output files with headers\n",
    "        with open(var_output_file_path, 'w+') as var_out_file:\n",
    "            var_out_file.write(f\"File Name{DELIMIT}Variable Id{DELIMIT}Variable Name\\n\")\n",
    "\n",
    "        with open(var_level_output_file_path, 'w+') as var_level_out_file:\n",
    "            var_level_out_file.write(f\"File Name{DELIMIT}Variable Id{DELIMIT}Variable Level{DELIMIT}Variable Level Description\\n\")\n",
    "\n",
    "        with open(var_type_output_file_path, 'w+') as var_type_out_file:\n",
    "            var_type_out_file.write(f\"File Name{DELIMIT}Variable Id{DELIMIT}Data Type\\n\")\n",
    "        \n",
    "        # Iterate through the directory and process the files\n",
    "        for path, subdirs, files in os.walk(directory_path):\n",
    "            for name in files:\n",
    "                file_count += 1  # Count the files processed\n",
    "                is_open = False\n",
    "                \n",
    "                # Process .DO files to extract variable names and levels\n",
    "                if name.endswith('.DO'):\n",
    "                    file_path = os.path.join(path, name)\n",
    "                    print(file_path)\n",
    "                    \n",
    "                    with open(file_path, 'r') as in_file:\n",
    "                        for line in in_file:\n",
    "                            # Handle 'label variable' lines to extract variable names\n",
    "                            if line.startswith('label variable'):\n",
    "                                with open(var_output_file_path, 'a') as var_out_file:\n",
    "                                    words = [w.replace(\"\\n\", \"\") for w in line.split(\" \") if w not in ['label', 'variable', '']]\n",
    "                                    variable_id = words[0]\n",
    "                                    variable_name = \" \".join(words[1:])\n",
    "                                    var_out_file.write(f\"{name}{DELIMIT}{variable_id}{DELIMIT}{variable_name}\\n\")\n",
    "                            \n",
    "                            # Begin processing 'label define' lines for variable levels\n",
    "                            elif line.startswith('label define'):\n",
    "                                is_open = True\n",
    "                                words = line.split(\" \")\n",
    "                                variable_id = words[2].replace(\"\\n\", \"\")\n",
    "                            \n",
    "                            # Capture variable levels\n",
    "                            elif is_open and not line.startswith(';'):\n",
    "                                with open(var_level_output_file_path, 'a') as var_level_out_file:\n",
    "                                    words = [w.replace(\"\\n\", \"\") for w in line.split(\" \") if w]\n",
    "                                    variable_level = words[0]\n",
    "                                    variable_level_description = \" \".join(words[1:])\n",
    "                                    var_level_out_file.write(f\"{name}{DELIMIT}{variable_id}{DELIMIT}{variable_level}{DELIMIT}{variable_level_description}\\n\")\n",
    "                            \n",
    "                            # End capturing variable levels\n",
    "                            elif is_open and line.startswith(';'):\n",
    "                                is_open = False\n",
    "                \n",
    "                # Process .DCT files to extract variable types\n",
    "                elif name.endswith('.DCT'):\n",
    "                    file_path = os.path.join(path, name)\n",
    "                    print(file_path)\n",
    "                    \n",
    "                    with open(file_path, 'r') as in_file:\n",
    "                        for line in in_file:\n",
    "                            # Skip unnecessary lines\n",
    "                            if line.startswith(\"infix\") or line.startswith(\"1 lines\") or line.startswith(\"}\"):\n",
    "                                continue\n",
    "                            else:\n",
    "                                with open(var_type_output_file_path, 'a') as var_type_out_file:\n",
    "                                    words = [w for w in line.split(\" \") if w not in ['', '\\n']]\n",
    "                                    variable_id = words[1]\n",
    "                                    variable_type = words[0]\n",
    "                                    var_type_out_file.write(f\"{name}{DELIMIT}{variable_id}{DELIMIT}{variable_type}\\n\")\n",
    "                \n",
    "                # Process .DTA files and convert them to CSV\n",
    "                elif name.endswith('.DTA'):\n",
    "                    file_path = os.path.join(path, name)\n",
    "                    print(file_path)\n",
    "                    \n",
    "                    # Read and convert .DTA file to CSV\n",
    "                    in_df = pd.read_stata(file_path, convert_categoricals=False)\n",
    "                    out_file_path = os.path.join(data_output_file_dir, f\"{name.replace('.DTA', '')}.csv\")\n",
    "                    in_df.to_csv(out_file_path, index=False)\n",
    "        \n",
    "        # Print summary of the process\n",
    "        print(f\"Total number of files processed: {file_count}\")\n",
    "        print(f\"Variable names written to: {var_output_file_path}\")\n",
    "        print(f\"Variable levels written to: {var_level_output_file_path}\")\n",
    "        print(f\"Variable data types written to: {var_type_output_file_path}\")\n",
    "        print(f\"CSV data saved to: {data_output_file_dir}\")\n",
    "        \n",
    "        elapsed_time = time.time() - start_time  # Calculate and display elapsed time\n",
    "        print(f\"Elapsed time in seconds: {elapsed_time:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca25d5-f9de-444e-a58b-6787dc486dc3",
   "metadata": {},
   "source": [
    "#### Target Country: Eygpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e2b8301-95c7-402c-a7e6-985c5590af52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing raw data files...\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGBR61DT\\EGBR61FL.DCT\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGBR61DT\\EGBR61FL.DO\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGBR61DT\\EGBR61FL.DTA\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGHR61DT\\EGHR61FL.DCT\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGHR61DT\\EGHR61FL.DO\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGHR61DT\\EGHR61FL.DTA\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGIR61DT\\EGIR61FL.DCT\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGIR61DT\\EGIR61FL.DO\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGIR61DT\\EGIR61FL.DTA\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGKR61DT\\EGKR61FL.DCT\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGKR61DT\\EGKR61FL.DO\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGKR61DT\\EGKR61FL.DTA\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGPR61DT\\EGPR61FL.DCT\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGPR61DT\\EGPR61FL.DO\n",
      "..\\resources\\raw_data\\extracted\\all\\EG\\EGPR61DT\\EGPR61FL.DTA\n",
      "Total number of files processed: 31\n",
      "Variable names written to: ..\\resources\\raw_data\\extracted\\variables\\EG\\variables_name.csv\n",
      "Variable levels written to: ..\\resources\\raw_data\\extracted\\variables\\EG\\variables_level.csv\n",
      "Variable data types written to: ..\\resources\\raw_data\\extracted\\variables\\EG\\variables_datatype.csv\n",
      "CSV data saved to: ..\\resources\\raw_data\\extracted\\data\\EG\n",
      "Elapsed time in seconds: 165.542\n"
     ]
    }
   ],
   "source": [
    "# Create directories for raw data extraction and output files for variables and data\n",
    "directory_path = make_mydir(f\"{raw_data_dir}/extracted/all/{country}/\")\n",
    "\n",
    "# Set paths for output CSV files to store variable names, levels, and data types\n",
    "var_output_file_path = os.path.join(make_mydir(f\"{raw_data_dir}/extracted/variables/{country}/\"),\n",
    "                                    \"variables_name.csv\")\n",
    "var_leve_output_file_path = os.path.join(make_mydir(f\"{raw_data_dir}/extracted/variables/{country}/\"),\n",
    "                                         \"variables_level.csv\")\n",
    "var_type_output_file_path = os.path.join(make_mydir(f\"{raw_data_dir}/extracted/variables/{country}/\"),\n",
    "                                         \"variables_datatype.csv\")\n",
    "\n",
    "# Set directory for saving the converted data files (from STATA to CSV)\n",
    "data_output_file_dir = make_mydir(f\"{raw_data_dir}/extracted/data/{country}/\")\n",
    "\n",
    "# Preprocess the input data by parsing variable information and converting files\n",
    "preprocess_input_data(directory_path=directory_path, \n",
    "                      var_output_file_path=var_output_file_path, \n",
    "                      var_level_output_file_path=var_leve_output_file_path,\n",
    "                      var_type_output_file_path=var_type_output_file_path,\n",
    "                      data_output_file_dir=data_output_file_dir\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c3a186-7bf0-42cd-88b4-14e2c18c2757",
   "metadata": {},
   "source": [
    "### Extract target input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dedecef-e3a2-4d50-a376-ed289d14f6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the selected variables file name: EG_selected_variables_id.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected variables: 235\n",
      "Sample of selected variables: ['hhid', 'hv009', 'hv025', 'hv201', 'hv204']\n"
     ]
    }
   ],
   "source": [
    "# After inspecting the extracted variable information, we selected 230 items (questionnaire items)\n",
    "# as independent variables from an initial pool of approximately 3,000 items.\n",
    "\n",
    "# Prompt the user to provide the path to the file containing the selected variable IDs.\n",
    "# In the current investigation, we use the following file which contains the selected variable IDs:\n",
    "# EG_selected_variables_id.csv\n",
    "file_name = input(\"Enter the name of the selected variables file name:\")\n",
    "selected_var_path = f'../user_input/{file_name}'\n",
    "\n",
    "# Read the selected variable IDs from the CSV file.\n",
    "selected_var_ids = [id[0] for id in pd.read_csv(selected_var_path).values]\n",
    "\n",
    "# Output the count and a sample of the selected variables.\n",
    "print(f\"Number of selected variables: {len(selected_var_ids)}\")\n",
    "print(f\"Sample of selected variables: {selected_var_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f32d23e0-80e3-46f8-a22b-316536395c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhid</th>\n",
       "      <th>hv009</th>\n",
       "      <th>hv025</th>\n",
       "      <th>hv201</th>\n",
       "      <th>hv204</th>\n",
       "      <th>hv205</th>\n",
       "      <th>hv206</th>\n",
       "      <th>hv207</th>\n",
       "      <th>hv208</th>\n",
       "      <th>hv209</th>\n",
       "      <th>...</th>\n",
       "      <th>sh29_22</th>\n",
       "      <th>sh29_23</th>\n",
       "      <th>sh29_24</th>\n",
       "      <th>sh29_25</th>\n",
       "      <th>sh29_26</th>\n",
       "      <th>sh29_27</th>\n",
       "      <th>sh29_28</th>\n",
       "      <th>sh29_29</th>\n",
       "      <th>sh29_30</th>\n",
       "      <th>sh29_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10706  5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10706 15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10706 24</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10706 34</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10706 43</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           hhid  hv009  hv025  hv201  hv204  hv205  hv206  hv207  hv208  \\\n",
       "0      10706  5      5      1   11.0  996.0   11.0    1.0    1.0    1.0   \n",
       "1      10706 15      3      1   11.0  996.0   11.0    1.0    0.0    1.0   \n",
       "2      10706 24      8      1   11.0  996.0   11.0    1.0    0.0    1.0   \n",
       "3      10706 34      4      1   11.0  996.0   11.0    1.0    0.0    1.0   \n",
       "4      10706 43      3      1   11.0  996.0   11.0    1.0    0.0    1.0   \n",
       "\n",
       "   hv209  ...  sh29_22  sh29_23  sh29_24  sh29_25  sh29_26  sh29_27  sh29_28  \\\n",
       "0    1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1    1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2    1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3    1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4    1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   sh29_29  sh29_30  sh29_31  \n",
       "0      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of DataFrame: (28175, 235)\n",
      "Extracted input data saved to file: ..\\resources\\data\\input\\input_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the survey type to filter relevant data files.\n",
    "survey_type = 'HR'\n",
    "\n",
    "# Retrieve the path of the data file matching the survey type.\n",
    "for path, subdirs, files in os.walk(f'{raw_data_dir}/extracted/data/{country}/'):\n",
    "    for file in files:\n",
    "        if survey_type in file:  # Check if the file contains the survey type.\n",
    "            data_file_path = os.path.join(path, file)  # Construct the full file path.\n",
    "            break\n",
    "\n",
    "# Load the data from the CSV file into a DataFrame.\n",
    "in_df = pd.read_csv(data_file_path)\n",
    "\n",
    "# Select only the columns corresponding to the chosen variable IDs.\n",
    "in_df = in_df[selected_var_ids]\n",
    "\n",
    "# Display the first few rows of the DataFrame and its size.\n",
    "display(in_df.head())\n",
    "print(f'Size of DataFrame: {in_df.shape}')\n",
    "\n",
    "# Prepare the output directory and file path for the extracted data.\n",
    "out_file_dir = make_mydir(\"../resources/data/input/\")\n",
    "out_file_path = os.path.join(out_file_dir, 'input_data.csv')\n",
    "\n",
    "# Save the filtered DataFrame to a CSV file.\n",
    "in_df.to_csv(out_file_path, index=False)\n",
    "print(f\"Extracted input data saved to file: {out_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd3347f-da82-4603-b224-71fefce8c233",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
